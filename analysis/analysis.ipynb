{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/a/lifeslice.csv: Total Rows: 5734 Outliers Removed: 2902 Rows Remaining: 2832\n",
      "../data/a/lifeslice.csv: Date Range: 2016-03-31 to 2017-01-28\n",
      "../data/a/imessage.csv: Total Rows: 19744 Outliers Removed: 6160 Rows Remaining: 13584\n",
      "../data/a/imessage.csv: Date Range: 2015-11-03 to 2017-01-30\n",
      "../data/a/facebook.csv: Total Rows: 26824 Outliers Removed: 7653 Rows Remaining: 19171\n",
      "../data/a/facebook.csv: Date Range: 2011-03-16 to 2016-12-11\n",
      "../data/a/dayone.csv: Total Rows: 1051 Outliers Removed: 321 Rows Remaining: 730\n",
      "../data/a/dayone.csv: Date Range: 2007-05-13 to 2017-01-29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cjroth/136.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import cufflinks as cf\n",
    "\n",
    "py.tools.set_credentials_file(username='cjroth', api_key='N7E7pw9PBszV5t4DVQqu')\n",
    "\n",
    "# Specify which participant to analyze and how to resample and roll up the data\n",
    "participant = 'a'\n",
    "resample_rule = '1d'\n",
    "rolling_mean_window = 60\n",
    "# scale = (-1, 1)\n",
    "scale = None\n",
    "timeframe = ('2016-04-01', '2017-02-01')\n",
    "\n",
    "if (not os.path.isdir('../data')):\n",
    "    raise Exception('Data directory does not exist. Are you sure you running this from the right directory?')\n",
    "\n",
    "data_dir = '../data/' + participant\n",
    "if (not os.path.isdir(data_dir)):\n",
    "    raise Exception('Participant does not exist.')\n",
    "\n",
    "# Specify which datasets to look for, which columns to use, and how to draw their lines on the chart\n",
    "datasets = [\n",
    "    # dataset      column                    datatype       linetype\n",
    "    ('lifeslice',  'emotions.valence',       'scale',       'g-'),\n",
    "    ('imessage',   'sentiment.comparative',  'scale',       'r-'),\n",
    "    ('facebook',   'sentiment.comparative',  'scale',       'b-'),\n",
    "    ('dayone',     'sentiment.comparative',  'scale',       'y-'),\n",
    "    ('750words',   'sentiment.comparative',  'scale',       'm-'),\n",
    "#     ('lifeslice',  'appearance.age',         'category',    'm-'),\n",
    "]\n",
    "\n",
    "# Specify how we define outliers\n",
    "def find_outliers(series):\n",
    "    ''' specifies how outliers are defined '''\n",
    "    iqr = (series.quantile(0.25) * 1.5, series.quantile(0.75) * 1.5)\n",
    "    outliers = (series < iqr[0]) | (series > iqr[1])\n",
    "    return outliers\n",
    "\n",
    "# Create a function to normalize values from -1 to 1\n",
    "def normalize(series):\n",
    "    min = series.min()\n",
    "    max = series.max()\n",
    "    return ((series - min) / (max - min) - 0.5) * 2\n",
    "\n",
    "def prepare_category(csv, column):\n",
    "\n",
    "    # Read the csv, merging `date` and `time` columns into a single `date_time` column of type Timestamp and use this as the index\n",
    "    raw = pd.read_csv(csv, parse_dates=[['date', 'time']], index_col=['date_time']).dropna()\n",
    "\n",
    "    # Convert the age column to categories\n",
    "    prepared = raw[column].astype('category')\n",
    "\n",
    "    # Remove datum that are not definite age ranges\n",
    "    prepared = prepared.cat.remove_categories(['Under 18','65+'])\n",
    "    prepared = prepared.dropna()\n",
    "\n",
    "    # Map age ranges to their mean age\n",
    "    prepared = prepared.apply(lambda x: {\n",
    "        '18 - 24' : 21.0,\n",
    "        '25 - 34' : 29.5,\n",
    "        '35 - 44' : 39.5,\n",
    "        '45 - 54' : 49.5,\n",
    "        '55 - 64' : 59.5\n",
    "    }[x]).astype('float')\n",
    "\n",
    "    # Resample by taking the mean value of each day\n",
    "    prepared = prepared.resample(resample_rule).mean()\n",
    "\n",
    "    # Fill in empty days by using the mean of surrounding days\n",
    "    prepared = prepared.fillna(prepared.mean())\n",
    "\n",
    "    # Calculate the rolling mean (aka simple moving average)\n",
    "    prepared = prepared.rolling(rolling_mean_window, center=True).mean()\n",
    "\n",
    "    return prepared, raw\n",
    "\n",
    "# Define a function that takes a csv file path and prepares the data to be analyzed and charted\n",
    "def prepare_scale(csv, column):\n",
    "\n",
    "    # Read the csv, merging `date` and `time` columns into a single `date_time` column of type Timestamp and use this as the index\n",
    "    raw = pd.read_csv(csv, parse_dates=[['date', 'time']], index_col=['date_time']).dropna()\n",
    "\n",
    "    # Remove outliers outside of the interquartile range (IQR) * 1.5\n",
    "    number_total = raw.shape[0]\n",
    "    outliers = find_outliers(raw[column])\n",
    "    raw = raw[~outliers]\n",
    "    number_remaining = raw.shape[0]\n",
    "    number_outliers = number_total - number_remaining\n",
    "    print(\"{csv}: Total Rows: {number_total} Outliers Removed: {number_outliers} Rows Remaining: {number_remaining}\".format(**locals()))\n",
    "\n",
    "    prepared = raw[column]\n",
    "\n",
    "    # Resample by taking the mean value of each day\n",
    "    prepared = raw[column].resample(resample_rule).mean()\n",
    "\n",
    "    # Fill in empty days by using the mean of surrounding days\n",
    "    prepared = prepared.fillna(prepared.mean())\n",
    "\n",
    "    # Calculate the rolling mean (aka simple moving average)\n",
    "    prepared = prepared.rolling(rolling_mean_window, center=True).mean()\n",
    "\n",
    "    # Normalize values to a range of -1 to 1\n",
    "    prepared = normalize(prepared)\n",
    "\n",
    "    # Print the start and end dates\n",
    "    range = tuple(i.strftime('%Y-%m-%d') for i in (prepared.index[0], prepared.index[-1]))\n",
    "    print(\"{csv}: Date Range: {range[0]} to {range[1]}\".format(**locals()))\n",
    "\n",
    "    return prepared, raw\n",
    "\n",
    "def prepare(raw):\n",
    "    \n",
    "    # Remove rows with empty values\n",
    "    raw = raw.dropna()\n",
    "\n",
    "    # Remove outliers outside of the interquartile range (IQR) * 1.5\n",
    "    # number_total = raw.size\n",
    "    outliers = find_outliers(raw)\n",
    "    raw = raw[~outliers]\n",
    "    # number_remaining = raw.size\n",
    "    # number_outliers = number_total - number_remaining\n",
    "    # print(\"Total Rows: {number_total} Outliers Removed: {number_outliers} Rows Remaining: {number_remaining}\".format(**locals()))\n",
    "\n",
    "    # Normalize values to a range of -1 to 1\n",
    "    raw = normalize(raw)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "# Create a new dataframe to hold the resampled, cleaned data for analysis\n",
    "index = pd.date_range(*(datetime.datetime.strptime(i, '%Y-%m-%d') for i in timeframe))\n",
    "data = pd.DataFrame(index=index)\n",
    "\n",
    "# Create a line chart\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.autofmt_xdate()\n",
    "if scale != None:\n",
    "    ax.set_ylim(*scale)\n",
    "\n",
    "# Set up a Bokeh chart\n",
    "# p1 = figure(x_axis_type='datetime', title='Chronist')\n",
    "# p1.grid.grid_line_alpha = 0.3\n",
    "# p1.xaxis.axis_label = 'Date'\n",
    "# p1.yaxis.axis_label = 'Value'\n",
    "# p1.legend.location = 'top_left'\n",
    "\n",
    "chart = [\n",
    "    'lifeslice.emotions.valence',\n",
    "    'imessage.sentiment.comparative',\n",
    "]\n",
    "\n",
    "colors = ['#B2DF8A', '#A6CEE3']\n",
    "\n",
    "# Prepare data and chart it\n",
    "for index, pair in enumerate(datasets):\n",
    "\n",
    "    dataset  = pair[0]\n",
    "    column   = pair[1]\n",
    "    datatype = pair[2]\n",
    "    linetype = pair[3]\n",
    "\n",
    "    # Define where the dataset CSV lives\n",
    "    csv = data_dir + '/' + dataset + '.csv'\n",
    "\n",
    "    label = dataset + '.' + column\n",
    "\n",
    "    # Skip this dataset if it does not exist for the participant\n",
    "    if (not os.path.exists(csv)):\n",
    "        continue\n",
    "\n",
    "    if (datatype == 'scale'):\n",
    "        data[label], raw = prepare_scale(csv, column)\n",
    "    else:\n",
    "        data[label], raw = prepare_category(csv, column)\n",
    "\n",
    "\n",
    "    if label in chart:\n",
    "\n",
    "        # Add the sentiment comparative rolling mean to the chart\n",
    "        ax.plot(data.index, data[label], linetype)\n",
    "\n",
    "#         p1.line(np.array(data.index, dtype=np.datetime64), data[label], color=colors[index], legend=label)\n",
    "\n",
    "data.to_csv(data_dir + '/combined.csv')\n",
    "\n",
    "# py.plotly.plot([{\n",
    "#     'x': data.index,\n",
    "#     'y': data[col],\n",
    "#     'name': col\n",
    "# }  for col in data.columns], filename='chronist', kind='scatter')\n",
    "\n",
    "# output_file('public/' + participant + '.html', title='Chronist: Participant ' + participant.upper() + ' Visualization')\n",
    "# show(gridplot([[p1]], responsive=True)) # open a browser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://plot.ly/pandas/time-series/\n",
    "\n",
    "# cf.datagen.lines(1,500).ta_plot(study='sma',periods=[13,21,55],title='Simple Moving Averages')\n",
    "\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# upper_bound = go.Scatter(\n",
    "#     name='Upper Bound',\n",
    "#     x=df['Time'],\n",
    "#     y=df['10 Min Sampled Avg']+df['10 Min Std Dev'],\n",
    "#     mode='lines',\n",
    "#     marker=dict(color=\"444\"),\n",
    "#     line=dict(width=0),\n",
    "#     fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "#     fill='tonexty' )\n",
    "\n",
    "# raw = prepare(raw['emotions.valence'])\n",
    "\n",
    "# trace_markers = go.Scatter(\n",
    "#     name='lifeslice.emotions.valence',\n",
    "#     x=raw.index,\n",
    "#     y=raw,\n",
    "#     mode=\"markers\",\n",
    "#     # line=dict(color='rgb(31, 119, 180)'),\n",
    "#     # fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "# )\n",
    "\n",
    "# trace = go.Scatter(\n",
    "#     name=data['lifeslice.emotions.valence'],\n",
    "#     x=data.index,\n",
    "#     y=data['lifeslice.emotions.valence'],\n",
    "#     mode=\"lines\",\n",
    "#     line=dict(color='rgb(31, 119, 180)'),\n",
    "#     # fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "#     fill='tonexty' )\n",
    "\n",
    "# lower_bound = go.Scatter(\n",
    "#     name='Lower Bound',\n",
    "#     x=df['Time'],\n",
    "#     y=df['10 Min Sampled Avg']-df['10 Min Std Dev'],\n",
    "#     marker=dict(color=\"444\"),\n",
    "#     line=dict(width=0),\n",
    "#     mode='lines' )\n",
    "\n",
    "# Trace order can be important\n",
    "# with continuous error bars\n",
    "# data = [lower_bound, trace, upper_bound]\n",
    "# d = [trace_markers, trace]\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     yaxis=dict(title='Wind speed (m/s)'),\n",
    "#     title='Chronist',\n",
    "#     showlegend = False)\n",
    "# fig = go.Figure(data=d, layout=layout)\n",
    "\n",
    "# IPython notebook\n",
    "# py.iplot(fig, filename='pandas-time-series-error-bars')\n",
    "\n",
    "# url = py.plotly.iplot(fig, filename='chronist')\n",
    "\n",
    "# py.tools.embed('https://plot.ly/~cjroth/136')\n",
    "\n",
    "raw.iplot(kind='histogram', filename='chronist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifeslice.emotions.valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>-0.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-14</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lifeslice.emotions.valence\n",
       "2016-04-01                         NaN\n",
       "2016-04-02                         NaN\n",
       "2016-04-03                         NaN\n",
       "2016-04-04                         NaN\n",
       "2016-04-05                         NaN\n",
       "2016-04-06                         NaN\n",
       "2016-04-07                         NaN\n",
       "2016-04-08                         NaN\n",
       "2016-04-09                         NaN\n",
       "2016-04-10                         NaN\n",
       "2016-04-11                         NaN\n",
       "2016-04-12                         NaN\n",
       "2016-04-13                         NaN\n",
       "2016-04-14                         NaN\n",
       "2016-04-15                         NaN\n",
       "2016-04-16                         NaN\n",
       "2016-04-17                         NaN\n",
       "2016-04-18                         NaN\n",
       "2016-04-19                         NaN\n",
       "2016-04-20                         NaN\n",
       "2016-04-21                         NaN\n",
       "2016-04-22                         NaN\n",
       "2016-04-23                         NaN\n",
       "2016-04-24                         NaN\n",
       "2016-04-25                         NaN\n",
       "2016-04-26                         NaN\n",
       "2016-04-27                         NaN\n",
       "2016-04-28                         NaN\n",
       "2016-04-29                         NaN\n",
       "2016-04-30                   -0.002055\n",
       "...                                ...\n",
       "2017-01-03                         NaN\n",
       "2017-01-04                         NaN\n",
       "2017-01-05                         NaN\n",
       "2017-01-06                         NaN\n",
       "2017-01-07                         NaN\n",
       "2017-01-08                         NaN\n",
       "2017-01-09                         NaN\n",
       "2017-01-10                         NaN\n",
       "2017-01-11                         NaN\n",
       "2017-01-12                         NaN\n",
       "2017-01-13                         NaN\n",
       "2017-01-14                         NaN\n",
       "2017-01-15                         NaN\n",
       "2017-01-16                         NaN\n",
       "2017-01-17                         NaN\n",
       "2017-01-18                         NaN\n",
       "2017-01-19                         NaN\n",
       "2017-01-20                         NaN\n",
       "2017-01-21                         NaN\n",
       "2017-01-22                         NaN\n",
       "2017-01-23                         NaN\n",
       "2017-01-24                         NaN\n",
       "2017-01-25                         NaN\n",
       "2017-01-26                         NaN\n",
       "2017-01-27                         NaN\n",
       "2017-01-28                         NaN\n",
       "2017-01-29                         NaN\n",
       "2017-01-30                         NaN\n",
       "2017-01-31                         NaN\n",
       "2017-02-01                         NaN\n",
       "\n",
       "[307 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
